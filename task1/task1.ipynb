{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51fe51d-44be-48b2-a276-5ac4ecd4fb93",
   "metadata": {},
   "source": [
    "# Assignment 1 - Finetuning YOLO on COCO Traffic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994404cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/tobias/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725fe953",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7315e62",
   "metadata": {},
   "source": [
    "For our first project we chose the provided **COCO Dataset**\n",
    "\n",
    "It is an open dataset for region segmentation, that is hosted as a challenge. As such, **the test set annotations are not available**.\n",
    "\n",
    "The COCO dataset has 80 object categories, including common objects like cars, bicycles, and animals, as well as more specific categories such as umbrellas, handbags, and sports equipment. For our task we will not need all of these, but luckily with the implementation of ultralytics we can select a subset of these to train on.\n",
    "\n",
    "Concretely we will group them as:\n",
    "### Pedestrians\n",
    "* Person\n",
    "* Dog\n",
    "* Cow\n",
    "* Horse\n",
    "* Cat\n",
    "\n",
    "### Vehicle\n",
    "* Motorcycle\n",
    "* Bus\n",
    "* Car\n",
    "* Truck\n",
    "* Train\n",
    "\n",
    "### Cyclist\n",
    "* Bicycle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750db610",
   "metadata": {},
   "source": [
    "TODO: visualize some of the stats of the dataset, as well as some example images with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b3948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a6351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d895f1f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662fb55",
   "metadata": {},
   "source": [
    "For a first attempt, we can use ultralytics' implementation of a training without any augmentations, which we can add later to check and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c196c",
   "metadata": {},
   "source": [
    "TODO: actually run and train the model with parameters setting like in: https://docs.ultralytics.com/modes/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a82cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"coco.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eda81",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696a834",
   "metadata": {},
   "source": [
    "TODO evaluate the model, consult this website.\n",
    "\n",
    "https://docs.ultralytics.com/modes/val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c976c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # load an official model\n",
    "model = YOLO(\"path/to/best.pt\")  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps  # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbea350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2811d5e4",
   "metadata": {},
   "source": [
    "## Video Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822959f0",
   "metadata": {},
   "source": [
    "For our task, we should create an annotate result from some video. With this, we should use a video of road traffic, which we then annotate with our trained model, image by image, comparing different trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66469e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # pretrained YOLO11n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model([\"image1.jpg\", \"image2.jpg\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_vehicles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
